{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 1: Load Data, Train and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import csv\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Datasets/train_label.pkl', 'rb') as f:\n",
    "    labels = pickle.load(f)\n",
    "    \n",
    "with open('Datasets/train_image.pkl', 'rb') as f:\n",
    "    x_train_unshuffled = pickle.load(f)\n",
    "    \n",
    "with open('Datasets/test_image.pkl', 'rb') as f:\n",
    "    x_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping Data. As required my the NN.\n",
    "x_train_unshuffled = np.array(x_train_unshuffled).reshape(-1, 28, 28, 1)\n",
    "x_test = np.array(x_test).reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Normalizing data. Mappind data from 0 to 1\n",
    "x_train_unshuffled = tf.keras.utils.normalize(x_train_unshuffled,axis = 1 )\n",
    "x_test = tf.keras.utils.normalize(x_test,axis = 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The labels in the dataset are: 0, 2, 3, 6. They are mapped with 4 classes of NN: 0, 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_class_map = {\n",
    "    0: 0,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    6: 3\n",
    "}\n",
    "\n",
    "class_label_map = {\n",
    "    0: 0,\n",
    "    1: 2,\n",
    "    2: 3,\n",
    "    3: 6\n",
    "}\n",
    "\n",
    "y_train_unshuffled = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    y_train_unshuffled.append(label_class_map[labels[i]])\n",
    "    \n",
    "y_train_unshuffled = np.array(y_train_unshuffled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Shuffling data prior to training. I am using sklearn's shuffle utility for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = sklearn.utils.shuffle(x_train_unshuffled, y_train_unshuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Basic NN Architecture | 2 Convolution Layers, 2 Dense Layers\n",
    "\n",
    "> Training Accuracy: 99% | Validation Accuracy: 87%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (2, 2), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Output Layer: Number of neurons = number of classe1s.\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "              metrics = (['accuracy'])\n",
    "             )\n",
    "model.fit(x_train, y_train, epochs=50, shuffle = True, validation_split= 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('TrainedModels/midas_cnn_v2.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 2: Load Saved Model, Run Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('TrainedModels/midas_cnn_v2.model')\n",
    "predictions = new_model.predict(x_test)\n",
    "len(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Testing some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1600\n",
    "plt.imshow(x_test[index].reshape(28,28))\n",
    "class_label_map[np.argmax(predictions[index])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_map[np.argmax(predictions[700])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Writing data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Mohd_Omama.csv', mode='w') as f:\n",
    "    writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow(['image_index', 'class'])\n",
    "    \n",
    "    for i in range(len(x_test)):\n",
    "        print(class_label_map[np.argmax(predictions[i])])\n",
    "        writer.writerow([i, class_label_map[np.argmax(predictions[i])] ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIDAS",
   "language": "python",
   "name": "midas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
